{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60d58334-e38b-411e-a787-19669b35276e",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "I've recently gotten a bunch of embeddings for each of Anthony Fantano's videos. In this notebook, I want to develop a rudimentary prototype for semantic search. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77422a56-705a-4fe5-96e0-3d4d65edabfe",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will help to set up the rest of the notebook. \n",
    "\n",
    "I'll start by changing my working directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603180e4-9c7f-4787-972b-b45ba4ee6978",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b6c0be-a7fc-4ad2-9c2e-4c8d896cffa8",
   "metadata": {},
   "source": [
    "Now, I'll import some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b13e402-4f9b-48a8-9fe8-02d3e156a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import requests\n",
    "import os\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "import numpy as np\n",
    "import json\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import math\n",
    "import traceback\n",
    "from time import sleep\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c997207d-fc87-4876-a7cd-20f9e9fa6b39",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "Next, I'm going to load in all of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a3a4c-5f17-48cb-ac62-06c6a135c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame containing all of the data scraped for each of the videos\n",
    "tnd_data_df_records = []\n",
    "for child_dir in tqdm(list(Path(\"data/theneedledrop_scraping/\").iterdir())):\n",
    "    \n",
    "    # Extract the video ID from the \n",
    "    cur_video_id = child_dir.name\n",
    "    \n",
    "    # Load in the details.json file\n",
    "    try:\n",
    "        with open(f\"data/theneedledrop_scraping/{cur_video_id}/details.json\", \"r\") as json_file:\n",
    "            cur_details_dict = json.load(json_file)\n",
    "    except:\n",
    "        cur_details_dict = {}\n",
    "        \n",
    "    # Load in the transcription.json file\n",
    "    try:\n",
    "        with open(f\"data/theneedledrop_scraping/{cur_video_id}/transcription.json\", \"r\") as json_file:\n",
    "            cur_transcription_dict = json.load(json_file)\n",
    "    except:\n",
    "        cur_transcription_dict = {}\n",
    "        \n",
    "    # Load in the embedding\n",
    "    try:\n",
    "        with open(f\"data/theneedledrop_scraping/{cur_video_id}/whole_video_embedding.json\", \"r\") as json_file:\n",
    "            whole_video_embedding = json.load(json_file)\n",
    "    except:\n",
    "        whole_video_embedding = None\n",
    "        \n",
    "    # Load in the enriched details dictionary\n",
    "    try:\n",
    "        with open(f\"data/theneedledrop_scraping/{cur_video_id}/enriched_details.json\", \"r\") as json_file:\n",
    "            cur_enriched_details_dict = json.load(json_file)\n",
    "    except:\n",
    "        cur_details_dict = {}\n",
    "        \n",
    "    # Create a \"record\" for this video\n",
    "    tnd_data_df_records.append({\n",
    "        \"video_id\": cur_video_id,\n",
    "        \"details_dict\": cur_details_dict,\n",
    "        \"transcription_dict\": cur_transcription_dict,\n",
    "        \"whole_video_embedding\": whole_video_embedding,\n",
    "        \"enriched_details_dict\": cur_enriched_details_dict\n",
    "    })\n",
    "    \n",
    "# Now, we want to create a DataFrame from the tnd_data_df_records\n",
    "tnd_data_df = pd.DataFrame.from_records(tnd_data_df_records)\n",
    "\n",
    "# Making the embeddings ndarrays instead of lists \n",
    "tnd_data_df[\"whole_video_embedding\"] = tnd_data_df[\"whole_video_embedding\"].apply(lambda x: np.asarray(x) if x is not None else None)\n",
    "\n",
    "# Add a \"transcription string\" column \n",
    "tnd_data_df[\"transcription_str\"] = tnd_data_df[\"transcription_dict\"].apply(lambda x: x['text'] if 'text' in x else None)\n",
    "\n",
    "# Add a couple of columns indicating how long each of the transcriptions are \n",
    "tnd_data_df[\"transcription_length\"] = tnd_data_df[\"transcription_str\"].apply(lambda x: len(x) if x is not None else None)\n",
    "tnd_data_df[\"transcription_approx_tokens\"] = tnd_data_df[\"transcription_str\"].apply(lambda x: int(math.ceil(len(x)/3.5)) if x is not None else None)\n",
    "\n",
    "# Add a couple of columns grabbing the title and URL of the video \n",
    "tnd_data_df[\"video_title\"] = tnd_data_df[\"details_dict\"].apply(lambda x: x['title'])\n",
    "tnd_data_df[\"video_url\"] = tnd_data_df[\"video_id\"].apply(lambda x: f\"https://www.youtube.com/watch?v={x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc585266-dd7e-4c96-a62e-17f70a8b4323",
   "metadata": {},
   "source": [
    "I'll also load in all of the segments for each video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be516f27-8f51-4301-8d42-b7e4527ae193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all of the JSON files containing the video segment embeddings\n",
    "video_segment_emb_dict = {}\n",
    "tnd_scraping_folder_path = Path(\"data/theneedledrop_scraping/\")\n",
    "for child_folder in tqdm(list(tnd_scraping_folder_path.iterdir())):\n",
    "    if child_folder.is_dir():\n",
    "        cur_video_id = child_folder.stem\n",
    "        video_segment_emb_path = Path(f\"data/theneedledrop_scraping/{cur_video_id}/video_segment_embeddings.json\")\n",
    "        if (video_segment_emb_path.exists()):\n",
    "            with open(video_segment_emb_path, \"r\") as json_file:\n",
    "                video_segment_emb_dict[cur_video_id] = json.load(json_file)\n",
    "                \n",
    "# Loading all of the embedding dictionaries into a single DataFrame\n",
    "segment_emb_df_list = []\n",
    "for cur_video_id, segment_dict_list in video_segment_emb_dict.items():\n",
    "    segmend_df = pd.DataFrame(segment_dict_list)\n",
    "    segmend_df[\"video_id\"] = cur_video_id\n",
    "    segment_emb_df_list.append(segmend_df)\n",
    "segment_emb_df = pd.concat(segment_emb_df_list)\n",
    "\n",
    "\n",
    "# Remove all of the segments without embeddings\n",
    "segment_emb_df = segment_emb_df[segment_emb_df[\"embedding\"].notna()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b95280c-4312-4c28-b0fe-57a2f75d64fe",
   "metadata": {},
   "source": [
    "# Methods\n",
    "Below, I'm going to write a couple of methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdab974-8167-4026-8c62-e6531d338955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will return a list of ndarrays, each representing text embeddings of \n",
    "# the text in each index of the input_text_list list\n",
    "def generate_embeddings(input_text_list, print_exceptions=False):\n",
    "    \n",
    "    # Get the OpenAI API key from the environment variables \n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "    \n",
    "    # Build the API request\n",
    "    url = \"https://api.openai.com/v1/embeddings\"\n",
    "    headers = CaseInsensitiveDict()\n",
    "    headers[\"Content-Type\"] = \"application/json\"\n",
    "    headers[\"Authorization\"] = \"Bearer \" + api_key\n",
    "    data = \"\"\"{\"input\": \"\"\" + json.dumps(input_text_list) + \"\"\",\"model\":\"text-embedding-ada-002\"}\"\"\"\n",
    "    \n",
    "    # Send the API request\n",
    "    resp = requests.post(url, headers=headers, data=data)\n",
    "    \n",
    "    # If the request was successful, return ndarrays of the embeddings. Otherwise, return None objects \n",
    "    if resp.status_code == 200:\n",
    "        return [np.asarray(data_object['embedding']) for data_object in resp.json()['data']]\n",
    "    else:\n",
    "        if (print_exceptions):\n",
    "            print(resp.json())\n",
    "        return [None for txt in input_text_list]\n",
    "    \n",
    "# This method will generate the embedding for a single string\n",
    "def generate_embedding(txt_input):\n",
    "    return (generate_embeddings([txt_input])[0])\n",
    "    \n",
    "# This method will return the cosine similarity of two ndarrays\n",
    "def cosine_sim(a, b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51013034-ca5d-4838-bfdd-7af4465d564c",
   "metadata": {},
   "source": [
    "# Whole-Video Search Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d91cd6a-0912-4f9c-af5c-142435a820fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate the search string, and then generate an embedding based off of these \n",
    "search_txt = \"taylor swift\"\n",
    "search_txt_emb = generate_embedding(search_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07245f8d-3d1f-4685-9a9e-bd7b74d23045",
   "metadata": {},
   "source": [
    "Now that we have this embedding, we can search the Fantano videos! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac4b4d-15f4-4d04-a5a1-f01f5df701b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search across all of the different embeddings to determine which videos are similar\n",
    "tnd_data_with_embs_df = tnd_data_df[tnd_data_df[\"whole_video_embedding\"].notna()].copy()\n",
    "search_result_sim = tnd_data_with_embs_df.copy()\n",
    "search_result_sim[\"cosine_sim_to_search\"] = search_result_sim[\"whole_video_embedding\"].apply(\n",
    "    lambda x: cosine_sim(search_txt_emb, x))\n",
    "search_result_sim = search_result_sim.sort_values(\"cosine_sim_to_search\", ascending=False)\n",
    "\n",
    "# We're going to print out the top_n results\n",
    "top_n = 10\n",
    "for idx, row in enumerate(list(search_result_sim.head(top_n).itertuples())):\n",
    "    markdown_str = f\"**#{idx+1}:** [{row.video_title}]({row.video_url})<br>Similarity: {row.cosine_sim_to_search:.3f}<br>\"\n",
    "    display(Markdown(markdown_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac81b11-29ac-4c84-8016-ccabcc3d3cdb",
   "metadata": {},
   "source": [
    "# Segment Search Prototype\n",
    "Next, I want to try and enable searching for videos on a segment level. \n",
    "\n",
    "I'll start again by specifying my search string, and generating the embedding for it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f438cac5-a889-4927-b8e7-f26119c98a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate the search string, and then generate an embedding based off of these \n",
    "search_txt = \"radiohead hyperpop meteorite godsend\"\n",
    "search_txt_emb = generate_embedding(search_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c5b421-66f1-4052-9586-f47e27c5af0c",
   "metadata": {},
   "source": [
    "Next, I'll iterate through each video's segments, and determine the similarity between that video's segments and the `search_txt_emb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1576e4a0-d894-4293-9f3c-b2c42e362494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the similarity between the segment embeddings and the search embedding \n",
    "segment_emb_sim_df = segment_emb_df.copy()\n",
    "segment_emb_sim_df[\"cosine_sim_to_search\"] = segment_emb_sim_df[\"embedding\"].apply(\n",
    "    lambda x: cosine_sim(search_txt_emb, x))\n",
    "\n",
    "# Sort this DataFrame by the similarity to the search embedding\n",
    "sorted_segment_emb_sim_df = segment_emb_sim_df.sort_values(\n",
    "    \"cosine_sim_to_search\", ascending=False).copy()\n",
    "\n",
    "# Determine the average similarity across each video \n",
    "avg_segment_sim_df = pd.DataFrame(sorted_segment_emb_sim_df.groupby(\"video_id\")[\n",
    "    \"cosine_sim_to_search\"].mean()).reset_index().sort_values(\"cosine_sim_to_search\", ascending=False)\n",
    "\n",
    "# Show the top n_to_show videos\n",
    "n_to_show = 5\n",
    "for idx, row in enumerate(list(avg_segment_sim_df.merge(tnd_data_df, on=\"video_id\").head(\n",
    "    n_to_show).itertuples())):\n",
    "    markdown_str = f\"**#{idx+1}:** [{row.video_title}]({row.video_url})<br>Similarity: {row.cosine_sim_to_search}\"\n",
    "    display(Markdown(markdown_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32821fb9-25a5-4d2e-abee-b38a3deb4adf",
   "metadata": {},
   "source": [
    "I also want to see the highest similarity segments: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a890c02-cb9e-4026-9df8-152cbf0a852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_show = 3\n",
    "for idx, row in enumerate(sorted_segment_emb_sim_df.merge(tnd_data_df, on=\"video_id\").head(n_to_show).itertuples()):\n",
    "    markdown_str = f\"**Segment #{idx+1}** (from [{row.video_title}]({row.video_url}))<br>Similarity: {row.cosine_sim_to_search}<br>{row.text}<br><br>\"\n",
    "    display(Markdown(markdown_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8594c46-7850-4a4c-acdf-ffccbafc31b9",
   "metadata": {},
   "source": [
    "Finally, another thing I can check out: the highest-similarity segments across different videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5a9dbd-8fc0-445b-aa0f-2d8278b29de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_sim_segments_per_video_df = sorted_segment_emb_sim_df[sorted_segment_emb_sim_df.groupby(\n",
    "    ['video_id'])['cosine_sim_to_search'].transform(max) == sorted_segment_emb_sim_df[\n",
    "    'cosine_sim_to_search']].copy()\n",
    "n_to_show = 5\n",
    "for idx, row in enumerate(high_sim_segments_per_video_df.merge(tnd_data_df, on=\"video_id\").head(n_to_show).itertuples()):\n",
    "    markdown_str = f\"**Segment #{idx+1}** (from [{row.video_title}]({row.video_url}))<br>Similarity: {row.cosine_sim_to_search}<br>{row.text}<br><br>\"\n",
    "    display(Markdown(markdown_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dadd02-d88d-479a-8c5b-4cd8d450d588",
   "metadata": {},
   "source": [
    "### \"Better\" Segment Search\n",
    "Another idea that I had: what if I grabbed the top 10 most similar segments from each video, and then got the average segment similarity for that video? That would filter out brief mentions, and return videos that were more generally relevant to the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df2156-1291-41a1-ac4c-e427f142265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate the search string, and then generate an embedding based off of these \n",
    "search_txt = \"masterful meteorite disintegration\"\n",
    "search_txt_emb = generate_embedding(search_txt)\n",
    "\n",
    "# Calculate the similarity between the segment embeddings and the search embedding \n",
    "segment_emb_sim_df = segment_emb_df.copy()\n",
    "segment_emb_sim_df[\"cosine_sim_to_search\"] = segment_emb_sim_df[\"embedding\"].apply(\n",
    "    lambda x: cosine_sim(search_txt_emb, x))\n",
    "\n",
    "# Sort this DataFrame by the similarity to the search embedding\n",
    "sorted_segment_emb_sim_df = segment_emb_sim_df.sort_values(\n",
    "    \"cosine_sim_to_search\", ascending=False).copy()\n",
    "\n",
    "grouped_sorted_segment_df = sorted_segment_emb_sim_df.groupby(\"video_id\")\n",
    "top_segments_per_video = grouped_sorted_segment_df.apply(\n",
    "    lambda x: x.sort_values(\"cosine_sim_to_search\", ascending=False).head(10)).reset_index(\n",
    "    drop=True).copy()\n",
    "top_videos_by_top_segments = top_segments_per_video.groupby(\"video_id\")[\n",
    "    \"cosine_sim_to_search\"].mean().reset_index().sort_values(\n",
    "    \"cosine_sim_to_search\", ascending=False).merge(tnd_data_df, on=\"video_id\").copy()\n",
    "\n",
    "n_to_show = 5\n",
    "for idx, row in enumerate(top_videos_by_top_segments.head(n_to_show).itertuples()):\n",
    "    markdown_str = f\"**Segment #{idx+1}** (from [{row.video_title}]({row.video_url}))<br>Similarity: {row.cosine_sim_to_search}\"\n",
    "    display(Markdown(markdown_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1b627-79ce-49f2-9204-d8be3256f065",
   "metadata": {},
   "source": [
    "# Main Method\n",
    "Now that I've done a couple of different experiments, I'm going to try and create a \"main\" method. When given a textual input, this method ought to search the entirety of the video corpus. \n",
    "\n",
    "This main method will assume that all of the data has been loaded. \n",
    "\n",
    "I'm going to start by embedding the user's input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7357c2-5167-4d00-996c-9c78c401af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate the search string, and then generate an embedding based off of these \n",
    "search_txt = \"masterful meteorite disintegration\"\n",
    "search_txt_emb = generate_embedding(search_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373ca86-4130-4dde-895b-6ff8b1e0af61",
   "metadata": {},
   "source": [
    "Next, I'm going to search each of the segments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac169fce-63bf-4509-8024-946bd8cad447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the similarity between the segment embeddings and the search embedding \n",
    "segment_emb_sim_df = segment_emb_df.copy()\n",
    "segment_emb_sim_df[\"cosine_sim_to_search\"] = segment_emb_sim_df[\"embedding\"].apply(\n",
    "    lambda x: cosine_sim(search_txt_emb, x))\n",
    "\n",
    "# Sort this DataFrame by the similarity to the search embedding\n",
    "sorted_segment_emb_sim_df = segment_emb_sim_df.sort_values(\n",
    "    \"cosine_sim_to_search\", ascending=False).copy()\n",
    "\n",
    "grouped_sorted_segment_df = sorted_segment_emb_sim_df.groupby(\"video_id\")\n",
    "top_segments_per_video = grouped_sorted_segment_df.apply(\n",
    "    lambda x: x.sort_values(\"cosine_sim_to_search\", ascending=False).head(10)).reset_index(\n",
    "    drop=True).copy()\n",
    "top_videos_by_top_segments = top_segments_per_video.groupby(\"video_id\")[\n",
    "    \"cosine_sim_to_search\"].mean().reset_index().sort_values(\n",
    "    \"cosine_sim_to_search\", ascending=False).merge(tnd_data_df, on=\"video_id\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184fd784-ceff-489d-a892-fbe1ac15a41f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
