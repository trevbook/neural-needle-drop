{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60d58334-e38b-411e-a787-19669b35276e",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "I've recently gotten a bunch of embeddings for each of Anthony Fantano's videos. In this notebook, I want to develop a rudimentary prototype for semantic search. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77422a56-705a-4fe5-96e0-3d4d65edabfe",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will help to set up the rest of the notebook. \n",
    "\n",
    "I'll start by changing my working directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "603180e4-9c7f-4787-972b-b45ba4ee6978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Data\\Personal Study\\Programming\\neural-needle-drop\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b6c0be-a7fc-4ad2-9c2e-4c8d896cffa8",
   "metadata": {},
   "source": [
    "Now, I'll import some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b13e402-4f9b-48a8-9fe8-02d3e156a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import requests\n",
    "import os\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "import numpy as np\n",
    "import json\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import math\n",
    "import traceback\n",
    "from time import sleep\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c997207d-fc87-4876-a7cd-20f9e9fa6b39",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "Next, I'm going to load in all of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e0a3a4c-5f17-48cb-ac62-06c6a135c00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 3974/3974 [00:25<00:00, 158.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame containing all of the data scraped for each of the videos\n",
    "tnd_data_df_records = []\n",
    "for child_dir in tqdm(list(Path(\"data/theneedledrop_scraping/\").iterdir())):\n",
    "    \n",
    "    # Extract the video ID from the \n",
    "    cur_video_id = child_dir.name\n",
    "    \n",
    "    # Load in the details.json file\n",
    "    try:\n",
    "        with open(f\"data/theneedledrop_scraping/{cur_video_id}/details.json\", \"r\") as json_file:\n",
    "            cur_details_dict = json.load(json_file)\n",
    "    except:\n",
    "        cur_details_dict = {}\n",
    "        \n",
    "    # Load in the transcription.json file\n",
    "    try:\n",
    "        with open(f\"data/theneedledrop_scraping/{cur_video_id}/transcription.json\", \"r\") as json_file:\n",
    "            cur_transcription_dict = json.load(json_file)\n",
    "    except:\n",
    "        cur_transcription_dict = {}\n",
    "        \n",
    "    # Load in the embedding\n",
    "    try:\n",
    "        with open(f\"data/theneedledrop_scraping/{cur_video_id}/whole_video_embedding.json\", \"r\") as json_file:\n",
    "            whole_video_embedding = json.load(json_file)\n",
    "    except:\n",
    "        whole_video_embedding = None\n",
    "        \n",
    "    # Create a \"record\" for this video\n",
    "    tnd_data_df_records.append({\n",
    "        \"video_id\": cur_video_id,\n",
    "        \"details_dict\": cur_details_dict,\n",
    "        \"transcription_dict\": cur_transcription_dict,\n",
    "        \"whole_video_embedding\": whole_video_embedding\n",
    "    })\n",
    "    \n",
    "# Now, we want to create a DataFrame from the tnd_data_df_records\n",
    "tnd_data_df = pd.DataFrame.from_records(tnd_data_df_records)\n",
    "\n",
    "# Making the embeddings ndarrays instead of lists \n",
    "tnd_data_df[\"whole_video_embedding\"] = tnd_data_df[\"whole_video_embedding\"].apply(lambda x: np.asarray(x) if x is not None else None)\n",
    "\n",
    "# Add a \"transcription string\" column \n",
    "tnd_data_df[\"transcription_str\"] = tnd_data_df[\"transcription_dict\"].apply(lambda x: x['text'] if 'text' in x else None)\n",
    "\n",
    "# Add a couple of columns indicating how long each of the transcriptions are \n",
    "tnd_data_df[\"transcription_length\"] = tnd_data_df[\"transcription_str\"].apply(lambda x: len(x) if x is not None else None)\n",
    "tnd_data_df[\"transcription_approx_tokens\"] = tnd_data_df[\"transcription_str\"].apply(lambda x: int(math.ceil(len(x)/3.5)) if x is not None else None)\n",
    "\n",
    "# Add a couple of columns grabbing the title and URL of the video \n",
    "tnd_data_df[\"video_title\"] = tnd_data_df[\"details_dict\"].apply(lambda x: x['title'])\n",
    "tnd_data_df[\"video_url\"] = tnd_data_df[\"video_id\"].apply(lambda x: f\"https://www.youtube.com/watch?v={x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b95280c-4312-4c28-b0fe-57a2f75d64fe",
   "metadata": {},
   "source": [
    "# Methods\n",
    "Below, I'm going to write a couple of methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cdab974-8167-4026-8c62-e6531d338955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will return a list of ndarrays, each representing text embeddings of \n",
    "# the text in each index of the input_text_list list\n",
    "def generate_embeddings(input_text_list, print_exceptions=False):\n",
    "    \n",
    "    # Get the OpenAI API key from the environment variables \n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "    \n",
    "    # Build the API request\n",
    "    url = \"https://api.openai.com/v1/embeddings\"\n",
    "    headers = CaseInsensitiveDict()\n",
    "    headers[\"Content-Type\"] = \"application/json\"\n",
    "    headers[\"Authorization\"] = \"Bearer \" + api_key\n",
    "    data = \"\"\"{\"input\": \"\"\" + json.dumps(input_text_list) + \"\"\",\"model\":\"text-embedding-ada-002\"}\"\"\"\n",
    "    \n",
    "    # Send the API request\n",
    "    resp = requests.post(url, headers=headers, data=data)\n",
    "    \n",
    "    # If the request was successful, return ndarrays of the embeddings. Otherwise, return None objects \n",
    "    if resp.status_code == 200:\n",
    "        return [np.asarray(data_object['embedding']) for data_object in resp.json()['data']]\n",
    "    else:\n",
    "        if (print_exceptions):\n",
    "            print(resp.json())\n",
    "        return [None for txt in input_text_list]\n",
    "    \n",
    "# This method will generate the embedding for a single string\n",
    "def generate_embedding(txt_input):\n",
    "    return (generate_embeddings([txt_input])[0])\n",
    "    \n",
    "# This method will return the cosine similarity of two ndarrays\n",
    "def cosine_sim(a, b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51013034-ca5d-4838-bfdd-7af4465d564c",
   "metadata": {},
   "source": [
    "# Whole-Video Search Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d91cd6a-0912-4f9c-af5c-142435a820fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate the search string, and then generate an embedding based off of these \n",
    "search_txt = \"ameer vann\"\n",
    "search_txt_emb = generate_embedding(search_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07245f8d-3d1f-4685-9a9e-bd7b74d23045",
   "metadata": {},
   "source": [
    "Now that we have this embedding, we can search the Fantano videos! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f0ac4b4d-15f4-4d04-a5a1-f01f5df701b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**#1:** [Ameer Vann - Emmanuel EP REVIEW](https://www.youtube.com/watch?v=zcn-Kp_OWfI)<br>Similarity: 0.785<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**#2:** [Various Artists - NOW That's What I Call Music, Vol. 69 COMPILATION REVIEW](https://www.youtube.com/watch?v=2ADxX13pFhU)<br>Similarity: 0.782<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**#3:** [ZelooperZ - Van Gogh's Left Ear ALBUM REVIEW](https://www.youtube.com/watch?v=9Dn926lHlKE)<br>Similarity: 0.772<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**#4:** [Paysage d'Hiver - Im Wald ALBUM REVIEW](https://www.youtube.com/watch?v=qwhoHT727TA)<br>Similarity: 0.772<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**#5:** [Myrkur - Mareridt ALBUM REVIEW](https://www.youtube.com/watch?v=NOvcBmZCRJ8)<br>Similarity: 0.770<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**#6:** [Clown Core - Van ALBUM REVIEW](https://www.youtube.com/watch?v=R68JzG7Vb7w)<br>Similarity: 0.768<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**#7:** [SXSW 2012 Vlog 2](https://www.youtube.com/watch?v=nbOzVokN5mc)<br>Similarity: 0.765<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**#8:** [The Velvet Underground & Nico - Self-Titled ALBUM REVIEW](https://www.youtube.com/watch?v=zaumyfPx3Ao)<br>Similarity: 0.764<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**#9:** [RECORD STORE DAY 2017 PICKS!!!!](https://www.youtube.com/watch?v=GnLciv6GeXE)<br>Similarity: 0.764<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**#10:** [SXSW 2012 Vlog 1](https://www.youtube.com/watch?v=hYRO6gXD7eA)<br>Similarity: 0.763<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Search across all of the different embeddings to determine which videos are similar\n",
    "tnd_data_with_embs_df = tnd_data_df[tnd_data_df[\"whole_video_embedding\"].notna()].copy()\n",
    "search_result_sim = tnd_data_with_embs_df.copy()\n",
    "search_result_sim[\"cosine_sim_to_search\"] = search_result_sim[\"whole_video_embedding\"].apply(\n",
    "    lambda x: cosine_sim(search_txt_emb, x))\n",
    "search_result_sim = search_result_sim.sort_values(\"cosine_sim_to_search\", ascending=False)\n",
    "\n",
    "# We're going to print out the top_n results\n",
    "top_n = 10\n",
    "for idx, row in enumerate(list(search_result_sim.head(top_n).itertuples())):\n",
    "    markdown_str = f\"**#{idx+1}:** [{row.video_title}]({row.video_url})<br>Similarity: {row.cosine_sim_to_search:.3f}<br>\"\n",
    "    display(Markdown(markdown_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84765b40-404a-4d07-98aa-29c226bb455a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
