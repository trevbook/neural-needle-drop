{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd5def7-2d58-41c3-87e8-f22250a3ca74",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "Now that I've played with both Pytube and OpenAI's Whisper, I think I should be able to start building out a pipeline that'll download some data about Anthony Fantano videos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86b01f8-9be7-4c6b-8de8-70e274b5c559",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will help to set up the rest of the notebook.\n",
    "\n",
    "I'll start by changing directories to the root of the repo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74a685a-c941-4757-894c-e0bb82b08304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Data\\Personal Study\\Programming\\neural-needle-drop\n"
     ]
    }
   ],
   "source": [
    "# Change the directory to the root of the repo\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbadf92-c88b-47dc-a0e5-143957c6630f",
   "metadata": {},
   "source": [
    "Next, I'll import a couple of different libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43687acd-43a7-4eb0-b02e-71084f5a0f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import subprocess\n",
    "import whisper\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import torch\n",
    "import json\n",
    "from Levenshtein import ratio\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import os\n",
    "\n",
    "# pytube-specific import statements\n",
    "from pytube import YouTube\n",
    "from pytube import Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52ef269-60b4-40fa-aad9-dd045b83f287",
   "metadata": {},
   "source": [
    "Finally, I'll set up Whisper by loading the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e71eacd-0fdb-441b-bf11-8f5e59e38b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the 'tiny.en' model into cuda in 1.84 seconds\n"
     ]
    }
   ],
   "source": [
    "# Determining whether we'll use GPU or CPU\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load in the model\n",
    "model_type = \"tiny.en\"\n",
    "start_time=time()\n",
    "whisper_model = whisper.load_model(model_type, device=DEVICE)\n",
    "print(f\"Loaded the '{model_type}' model into {DEVICE} in {time()-start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58730b5-199a-4226-bc5c-4ff90d36433d",
   "metadata": {},
   "source": [
    "# Methods\n",
    "Below, I'm going to try and build up a couple of methods that're helpful for building a pipeline. Eventually, if I were to take this out of a Jupyter Notebook, it would behoove me to have a lot of this code compartmentalized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a387105b-63f8-4235-8f91-c96c336a0fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will retrieve all of the video URLs for a particular channel\n",
    "def get_channel_video_urls(channel):\n",
    "    \n",
    "    # Creating a Channel object\n",
    "    channel_object = Channel(f'https://www.youtube.com/c/{channel}')\n",
    "\n",
    "    # Determining all of his videos\n",
    "    all_video_urls = channel_object.video_urls\n",
    "    return all_video_urls\n",
    "\n",
    "# This method will convert an m4a file to mp3\n",
    "def convert_m4a_to_mp3(input_file_path, output_file_path):\n",
    "    \n",
    "    # Import the necessary library\n",
    "    import subprocess\n",
    "    \n",
    "    # Generate the ffmpeg command we'll use\n",
    "    command = f\"\"\"ffmpeg -i {input_file_path} {output_file_path}\"\"\"\n",
    "\n",
    "    # Run the command\n",
    "    rsp = subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d76f5688-3289-4f95-890d-ff0e641d422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will attempt to download the linked YouTube video and save an .mp3 at a particular path\n",
    "def download_video_mp3(video_url, output_file_path):\n",
    "    \n",
    "    # Creating a YouTube object for this video\n",
    "    video = YouTube(video_url)\n",
    "\n",
    "    # Find the highest-bitrate .m4a audio stream\n",
    "    highest_bitrate_mp4_audio_stream = None\n",
    "    highest_bitrate_found = 0\n",
    "    for stream in video.streams.filter(only_audio=True):\n",
    "        if (stream.mime_type == \"audio/mp4\"):\n",
    "            stream_bitrate = int(stream.abr.split(\"kbps\")[0])\n",
    "            if (stream_bitrate > highest_bitrate_found):\n",
    "                highest_bitrate_mp4_audio_stream = stream\n",
    "                highest_bitrate_found = stream_bitrate\n",
    "\n",
    "    # Create a data/ folder if it doesn't exist\n",
    "    data_folder_path = Path(output_file_path.parent)\n",
    "    data_folder_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # Download the audio for this YouTube video \n",
    "    highest_bitrate_mp4_audio_stream.download(output_path=data_folder_path, \n",
    "                                              filename=output_file_path.stem+\".m4a\",\n",
    "                                              skip_existing=False)\n",
    "\n",
    "    # Now, convert this audio to .mp3, and then delete the .m4a file\n",
    "    convert_m4a_to_mp3(input_file_path=f\"{data_folder_path}/{output_file_path.stem}.m4a\", \n",
    "                       output_file_path=output_file_path)\n",
    "\n",
    "    # Remove the file\n",
    "    os.remove(f\"{data_folder_path}/{output_file_path.stem}.m4a\")\n",
    "    \n",
    "# This method will return a JSON of a particular video's video_details\n",
    "def get_video_details(video_url):\n",
    "    \n",
    "    # Convert the video to a YouTube object\n",
    "    video = YouTube(video_url)\n",
    "    \n",
    "    # Get the details for this video\n",
    "    video_details = video.vid_info[\"videoDetails\"]\n",
    "    \n",
    "    # Add the publication date to the video details\n",
    "    video_details[\"publish_date\"] = video.publish_date\n",
    "    \n",
    "    # Return the video details\n",
    "    return video_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "324c1986-fd38-4f5c-99a6-f79d1a90dc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will transcribe an mp3 and return the transcription as a dictionary\n",
    "def transcribe_mp3(mp3_file_path):\n",
    "    return whisper_model.transcribe(str(mp3_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b7df711-3da9-44c2-8498-ad5ddb151425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will return the \"Watch URL\" of a particular video when given the Video ID\n",
    "def generate_watch_url(videoId):\n",
    "    return f\"https://www.youtube.com/watch?v={videoId}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cffa7e-82dc-4787-9908-3179efc41141",
   "metadata": {},
   "source": [
    "# Experimenting\n",
    "First thing I want to try: download a **ton** of the NeedleDrop videos. When I say \"download\", I want to try and grab: \n",
    "\n",
    "- The audio associated with the video\n",
    "- The details associated with the video\n",
    "- The transcription of the video \n",
    "\n",
    "In theory, this ought to be enough to use for future experiments. I could tweak the format of how I'm saving each of these, but ultimately, this will be a \"proof of concept\" for the workflow of an on-demand Fantano video scraper. \n",
    "\n",
    "**NOTE:** It's unclear as to whether or not YouTube really likes the fact that you're scraping videos from them, so it'll be important to be mindful of this when trying to access information. [Make sure to rate limit.](https://github.com/pytube/pytube/issues/97) In the future, I'll try and *really* slow down the rate at which I'm scraping this information, seeing as I don't want to get IP-banned. (I should also try to use a VPN when doing this.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d08362e-13d0-4c42-9df5-bf907e12718f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████████▎                                                               | 1419/3974 [08:08<08:31,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran into an error when scraping the video details for https://www.youtube.com/watch?v=N65_VUOVT6o.\n",
      "Sleeping for a while and continuing...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████████████████████▋                            | 2836/3974 [13:33<06:04,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran into an error when scraping the video details for https://www.youtube.com/watch?v=hwEA9vhpQDA.\n",
      "Sleeping for a while and continuing...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████████████████▎                           | 2861/3974 [15:10<09:40,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran into an error when scraping the video details for https://www.youtube.com/watch?v=EC9-QwUEaoc.\n",
      "Sleeping for a while and continuing...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████████████████████                | 3334/3974 [16:59<02:55,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran into an error when scraping the video details for https://www.youtube.com/watch?v=K-J6VwasuOg.\n",
      "Sleeping for a while and continuing...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████████████████████████████████████████████████████████▎        | 3625/3974 [18:22<01:42,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran into an error when scraping the video details for https://www.youtube.com/watch?v=HzUdHq42Z6A.\n",
      "Sleeping for a while and continuing...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 3974/3974 [20:54<00:00,  3.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Grabbing all of the video URLs for theneedledrop\n",
    "needledrop_video_urls = get_channel_video_urls(\"theneedledrop\")\n",
    "\n",
    "# Determine a minimum sleep time \n",
    "min_sleep_time = 20\n",
    "\n",
    "# Iterate through the first couple videos within Anthony Fantano's URL list and \n",
    "# download some of their information\n",
    "for video_url in tqdm(needledrop_video_urls):\n",
    "    \n",
    "    # Determine where to save the contents of this loop by extracting the video ID \n",
    "    video_id = video_url.split(\"=\")[-1]\n",
    "    main_output_path = Path(f\"data/theneedledrop_scraping/{video_id}/\")\n",
    "    main_output_path.mkdir(exist_ok=True, parents=True)\n",
    "    mp3_output_path = Path(f\"{main_output_path}/audio.mp3\")\n",
    "    details_output_path = Path(f\"{main_output_path}/details.json\")\n",
    "    transcription_output_path = Path(f\"{main_output_path}/transcription.json\")\n",
    "    \n",
    "    # Don't scrape this file if these already exist\n",
    "    if (mp3_output_path.exists() and details_output_path.exists() and transcription_output_path.exists()):\n",
    "        continue\n",
    "    \n",
    "    # Try to grab the video details\n",
    "    try:\n",
    "        \n",
    "        # Grab the video details, and then sleep a random amount of time \n",
    "        video_details = get_video_details(video_url)\n",
    "        sleep(randint(min_sleep_time, min_sleep_time+5))\n",
    "        \n",
    "        # Save the video details\n",
    "        with open(details_output_path, \"w\") as json_file:\n",
    "            json.dump(video_details, json_file, indent=2)\n",
    "        \n",
    "    # If you run into some sort of error, skip this video\n",
    "    except:\n",
    "        print(f\"Ran into an error when scraping the video details for {video_url}.\\nSleeping for a while and continuing...\\n\")\n",
    "        sleep(randint(65, 75))\n",
    "        continue\n",
    "        \n",
    "    # Try to download the video MP3\n",
    "    try:\n",
    "        \n",
    "        # Download the MP3 audio for this video\n",
    "        download_video_mp3(video_url, mp3_output_path)\n",
    "        sleep(randint(min_sleep_time, min_sleep_time+5))\n",
    "    \n",
    "    # If you run into some sort of error, skip this video\n",
    "    except:\n",
    "        print(f\"Ran into an error when scraping the video details for {video_url}.\\nSleeping for a while and continuing...\\n\")\n",
    "        sleep(randint(65, 75))\n",
    "        continue\n",
    "\n",
    "    # Transcribe the audio\n",
    "    transcription = transcribe_mp3(mp3_output_path)\n",
    "    \n",
    "    # Save the transcription\n",
    "    with open(transcription_output_path, \"w\") as json_file:\n",
    "        json.dump(transcription, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7610865e-0da9-4812-8aff-eaf0f64d7108",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
