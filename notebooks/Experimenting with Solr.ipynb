{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "I wanted to configure a Solr index within a Docker container, and I found the library `pysolr`. I'm going to play around with it within this notebook! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will help to set up the rest of the notebook.\n",
    "\n",
    "I'll start by changing the working directory to the root of the repo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\data\\programming\\neural-needle-drop\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'm going to import some modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "from pysolr import Solr\n",
    "import requests\n",
    "import mysql.connector\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm also going to set up my MySQL cursor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the connection to the MySQL server\n",
    "cnx = mysql.connector.connect(\n",
    "    user='root', password=os.getenv(\"MYSQL_PASSWORD\"), \n",
    "    host='localhost', database='neural-needle-drop')\n",
    "\n",
    "# Create a cursor \n",
    "cursor = cnx.cursor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods \n",
    "The cells below will help throughout the rest of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_field_to_schema(field_def, core_name, solr_url=\"http://localhost:8983/solr/\"):\n",
    "\n",
    "    \"\"\"This method will add a field to the schema for a given core\"\"\"\n",
    "\n",
    "    core_url = f\"{solr_url}{core_name}\"\n",
    "    solr_cmd = {'add-field': field_def}\n",
    "    r = requests.post(core_url + '/schema', json=solr_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_to_df(query, print_error=False):\n",
    "    '''Query the active MySQL database and return results in a DataFrame'''\n",
    "\n",
    "    # Try to return the results as a DataFrame\n",
    "    try:\n",
    "        # Execute the query\n",
    "        cursor.execute(query)\n",
    "\n",
    "        # Fetch the results \n",
    "        res = cursor.fetchall()\n",
    "\n",
    "        # Return a DataFrame\n",
    "        return pd.DataFrame(res, columns=[i[0] for i in cursor.description])\n",
    "\n",
    "    # If we run into an Exception, return None\n",
    "    except Exception as e:\n",
    "        if (print_error):\n",
    "            print(f\"Ran into the following error:\\n{e}\\nStack trace:\")\n",
    "            print(traceback.format_exc())\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring the Index\n",
    "I'm going to start by defining a schema, and then updating the `neural-needledrop` core to ensure that this schema is in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema fields\n",
    "fields = [\n",
    "    {\"name\": \"transcription\", \n",
    "    \"type\": \"text_general\", \n",
    "    \"stored\": True, \n",
    "    \"indexed\": True, \n",
    "    \"required\": False, \n",
    "    \"multiValued\": False}\n",
    "]\n",
    "\n",
    "# Update the schema\n",
    "for field in fields:\n",
    "    add_field_to_schema(field, 'neural-needledrop', solr_url=\"http://localhost:8983/solr/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Data to the Index\n",
    "Now that I've properly configured the index, I ought to add some data. First, I should actually *try* to add the data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all of the transcription data\n",
    "tnd_transcription_data_df = query_to_df(\"SELECT * FROM transcriptions\", print_error=True)\n",
    "\n",
    "# Transform the tnd_transcription_data_df to only have the video ID and the transcription\n",
    "full_transcriptions_df = tnd_transcription_data_df.query(\"segment==-1\")[[\"id\", \"text\"]].rename(columns={\"text\": \"transcription\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this data loaded, we can start populating the Solr core. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dicts from the transcription DataFrame\n",
    "upload_data = [{\"id\": row.id, \"transcription\": row.transcription} for row in full_transcriptions_df.itertuples()]\n",
    "\n",
    "# Upload this data to the Solr core\n",
    "url = f'http://localhost:8983/solr/neural-needledrop/update/json/docs?commit=true'\n",
    "headers = {'content-type': 'application/json'}\n",
    "r = requests.post(url, data=json.dumps(upload_data), headers=headers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying the Core\n",
    "I've got data in the core now. With this in mind, I want to try and query something! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_with_highlighting(query_string):\n",
    "\n",
    "    \"\"\"\n",
    "    This method will query the transcriptions with the given `query_string`. It'll return a couple of different DataFrames: \n",
    "\n",
    "    - `results_df` - this is a DataFrame of (id, score) tuples\n",
    "    - `highlights_df` - this is a DataFrame of all of the \n",
    "    \"\"\"\n",
    "\n",
    "    params = {\n",
    "        'q': 'transcription:' + query_string,\n",
    "        'hl': 'true',\n",
    "        'hl.fl': 'transcription',\n",
    "        'fl': 'id, score'\n",
    "    }\n",
    "    response = requests.get('http://localhost:8983/solr/neural-needledrop/select', params=params)\n",
    "    results = response.json()\n",
    "\n",
    "    # Creating the results and highlights DataFrames\n",
    "    results_df = pd.DataFrame.from_records(results[\"response\"][\"docs\"])\n",
    "    highlights_df = pd.DataFrame(results[\"highlighting\"]).T.reset_index().rename(columns={\"index\": \"id\"})\n",
    "    highlights_df = highlights_df.merge(results_df, on=\"id\")\n",
    "    \n",
    "    # Return both of the DataFrames I created\n",
    "    return results_df, highlights_df\n",
    "\n",
    "query = \"in rainbows\"\n",
    "results_df, highlights_df = query_with_highlighting(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"This is thanks largely <em>in</em> part to the classic records he dropped under the microphone's name <em>in</em> the early 2000s. \"]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlights_df.iloc[0].transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70b6d7546de29863a58b9c57a86bc7d85299cc84f1fdf81f78934173ede7c021"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
