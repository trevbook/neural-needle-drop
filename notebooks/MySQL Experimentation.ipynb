{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "I want to get a little familiar with MySQL, and a part of that is going to be using Python to interface with the server that I've set up. This notebook will contain some of my initial experimentation. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will help to set up the rest of the notebook. \n",
    "\n",
    "I'll start by changing my working directory to the root of the repo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\data\\programming\\neural-needle-drop\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll import a couple of important Python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import json\n",
    "import os\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up MySQL Connector\n",
    "I also want to set up the MySQL Connector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the connection to the MySQL server\n",
    "cnx = mysql.connector.connect(\n",
    "    user='root', password=os.getenv(\"MYSQL_PASSWORD\"), \n",
    "    host='localhost', database='neural-needle-drop')\n",
    "\n",
    "# Create a cursor \n",
    "cursor = cnx.cursor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Populating Table\n",
    "One of the first things I want to do: try and populate a table within the MySQL database. I'm going to follow [this tutorial](https://dev.mysql.com/doc/connector-python/en/connector-python-example-cursor-transaction.html) on populating a table with some data. \n",
    "\n",
    "First thing's first: I need to load in some of the data. I'll load everything into a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3974/3974 [03:35<00:00, 18.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>title</th>\n",
       "      <th>lengthSeconds</th>\n",
       "      <th>keywords</th>\n",
       "      <th>channelId</th>\n",
       "      <th>isOwnerViewing</th>\n",
       "      <th>shortDescription</th>\n",
       "      <th>isCrawlable</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>allowRatings</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>author</th>\n",
       "      <th>isPrivate</th>\n",
       "      <th>isUnpluggedCorpus</th>\n",
       "      <th>isLiveContent</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>inferred_video_type</th>\n",
       "      <th>inferred_review_score</th>\n",
       "      <th>spotify_linkages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--YnsRamkzc</td>\n",
       "      <td>Joey Bada$$- 1999 ALBUM REVIEW</td>\n",
       "      <td>418</td>\n",
       "      <td>[joey badass, joey bada$$, new york, album, 19...</td>\n",
       "      <td>UCt7fwAhXDy3oNFTAzF2o8Pw</td>\n",
       "      <td>False</td>\n",
       "      <td>Listen: http://theneedledrop.com/2012/06/joey-...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'thumbnails': [{'url': 'https://i.ytimg.com/v...</td>\n",
       "      <td>True</td>\n",
       "      <td>365830</td>\n",
       "      <td>theneedledrop</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2012-06-18 00:00:00</td>\n",
       "      <td>album_review</td>\n",
       "      <td>7.0</td>\n",
       "      <td>{'album': [{'review_album': '5ra51AaWF3iVebyhl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId                           title lengthSeconds  \\\n",
       "0  --YnsRamkzc  Joey Bada$$- 1999 ALBUM REVIEW           418   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [joey badass, joey bada$$, new york, album, 19...   \n",
       "\n",
       "                  channelId  isOwnerViewing  \\\n",
       "0  UCt7fwAhXDy3oNFTAzF2o8Pw           False   \n",
       "\n",
       "                                    shortDescription  isCrawlable  \\\n",
       "0  Listen: http://theneedledrop.com/2012/06/joey-...         True   \n",
       "\n",
       "                                           thumbnail  allowRatings viewCount  \\\n",
       "0  {'thumbnails': [{'url': 'https://i.ytimg.com/v...          True    365830   \n",
       "\n",
       "          author  isPrivate  isUnpluggedCorpus  isLiveContent  \\\n",
       "0  theneedledrop      False              False          False   \n",
       "\n",
       "          publish_date inferred_video_type  inferred_review_score  \\\n",
       "0  2012-06-18 00:00:00        album_review                    7.0   \n",
       "\n",
       "                                    spotify_linkages  \n",
       "0  {'album': [{'review_album': '5ra51AaWF3iVebyhl...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in all of the data from theneedledrop_scraping folder\n",
    "tnd_data_df_records = []\n",
    "tnd_embeddings_df_records = []\n",
    "tnd_segment_embeddings_df_records = []\n",
    "tnd_transcriptions_df_records = []\n",
    "for child_dir in tqdm(list(Path(\"data/theneedledrop_scraping/\").iterdir())):\n",
    "    if (child_dir.is_dir()):\n",
    "\n",
    "        # Load in the enriched details for this video \n",
    "        enriched_details_path = Path(f\"{child_dir}/enriched_details.json\")\n",
    "        if (enriched_details_path.exists()):\n",
    "            with open(enriched_details_path, \"r\") as json_file:\n",
    "                tnd_data_df_records.append(json.load(json_file))\n",
    "\n",
    "        # Load in the whole-video embedding for this video \n",
    "        whole_video_embedding_path = Path(f\"{child_dir}/whole_video_embedding.json\")\n",
    "        if (whole_video_embedding_path.exists()):\n",
    "            with open(whole_video_embedding_path, \"r\") as json_file:\n",
    "                tnd_embeddings_df_records.append(\n",
    "                    {\"video_id\": child_dir.stem,\n",
    "                     \"embedding\": json.load(json_file)})\n",
    "\n",
    "        # Load in the segment embeddings for this video \n",
    "        segment_embedding_path = Path(f\"{child_dir}/video_segment_embeddings.json\")\n",
    "        if (segment_embedding_path.exists()):\n",
    "            with open(segment_embedding_path, \"r\") as json_file:\n",
    "                tnd_segment_embeddings_df_records.append({\n",
    "                    \"video_id\": child_dir.stem,\n",
    "                    \"embedding\": json.load(json_file)\n",
    "                })\n",
    "\n",
    "        # Load in the transcription for this video\n",
    "        transcription_path = Path(f\"{child_dir}/transcription.json\")\n",
    "        if (transcription_path.exists()):\n",
    "            with open(transcription_path, \"r\") as json_file:\n",
    "                tnd_transcriptions_df_records.append({\n",
    "                    \"video_id\": child_dir.stem,\n",
    "                    \"transcription_dict\": json.load(json_file)})\n",
    "\n",
    "# Create the DataFrames\n",
    "tnd_data_df = pd.DataFrame.from_records(tnd_data_df_records)\n",
    "tnd_embeddings_df = pd.DataFrame.from_records(tnd_embeddings_df_records)\n",
    "tnd_segment_embeddings_df = pd.DataFrame.from_records(tnd_segment_embeddings_df_records)\n",
    "tnd_transcription_df = pd.DataFrame.from_records(tnd_transcriptions_df_records)\n",
    "\n",
    "# Show the head of the tnd_data_df\n",
    "tnd_data_df.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Information\n",
    "With this data in hand, I should be able to load some of it into the SQL server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will try and return the thumbnail URL \n",
    "def retrieve_thumbnail_url(row):\n",
    "    try: return row.thumbnail[\"thumbnails\"][-1]['url']\n",
    "    except: return None\n",
    "\n",
    "# Iterate through each of the rows in the tnd_data_df\n",
    "for row in tqdm(list(tnd_data_df.itertuples())):\n",
    "\n",
    "    # Create the query from some of the information in this row \n",
    "    insert_query = \"\"\"\n",
    "    REPLACE INTO video_details\n",
    "        (id, title, length, channel_id, description, \n",
    "        view_ct, channel_name, publish_date, url, thumbnail_url)\n",
    "        VALUES (%(id)s, %(title)s, %(length)s, %(channel_id)s, \n",
    "        %(description)s, %(view_ct)s, %(channel_name)s, %(publish_date)s,\n",
    "        %(url)s, %(thumbnail_url)s)\n",
    "    \"\"\"\n",
    "\n",
    "    # We'll specify the data that we'll be injecting into the table\n",
    "    insert_data = {\n",
    "        \"id\": row.videoId,\n",
    "        \"title\": row.title,\n",
    "        \"length\": row.lengthSeconds,\n",
    "        \"channel_id\": row.channelId,\n",
    "        \"description\": row.shortDescription,\n",
    "        \"view_ct\": row.viewCount,\n",
    "        \"channel_name\": row.author,\n",
    "        \"publish_date\": row.publish_date,\n",
    "        \"url\": f\"https://www.youtube.com/watch?v={row.videoId}\",\n",
    "        \"thumbnail_url\": retrieve_thumbnail_url(row)\n",
    "    }\n",
    "\n",
    "    # Execute this query \n",
    "    cursor.execute(insert_query, insert_data)\n",
    "\n",
    "# Now that we're done with adding all of the data, we'll commit it \n",
    "cnx.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole-Video Embeddings\n",
    "I also want to upload some of the video embeddings to the MySQL server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine how many segments are in the transcription for this particular video\n",
    "tnd_transcription_df[\"segment_ct\"] = tnd_transcription_df[\"transcription_dict\"].apply(\n",
    "    lambda x: len(x['segments']))\n",
    "\n",
    "# Merge the segment counts into the video embedding dictionary \n",
    "tnd_embeddings_df = tnd_embeddings_df.merge(tnd_transcription_df[[\"video_id\", \"segment_ct\"]], how=\"left\", on=\"video_id\").copy()\n",
    "\n",
    "# Add in the type of the embedding\n",
    "tnd_embeddings_df[\"embedding_type\"] = \"whole_video\"\n",
    "\n",
    "# Determine the start_segment and end_segment\n",
    "tnd_embeddings_df[\"start_segment\"] = 0\n",
    "tnd_embeddings_df[\"end_segment\"] = tnd_embeddings_df[\"segment_ct\"].apply(lambda x: x-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this data transformed like it is, we should be able to ingest it into the server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each of the rows in the tnd_data_df\n",
    "for row in tqdm(list(tnd_embeddings_df.itertuples())):\n",
    "\n",
    "    # Create the query from some of the information in this row \n",
    "    insert_query = \"\"\"\n",
    "    REPLACE INTO embeddings\n",
    "        (id, video_id, embedding, embedding_type,\n",
    "         start_segment, end_segment, segment_length)\n",
    "        VALUES (%(id)s, %(video_id)s, %(embedding)s, %(embedding_type)s, \n",
    "                %(start_segment)s, %(end_segment)s, %(segment_length)s)\n",
    "    \"\"\"\n",
    "\n",
    "    # We'll specify the data that we'll be injecting into the table\n",
    "    insert_data = {\n",
    "        \"id\": f\"{row.video_id}_{row.start_segment}_{row.end_segment}\",\n",
    "        \"video_id\": row.video_id,\n",
    "        \"embedding\": np.array(row.embedding).tobytes(),\n",
    "        \"embedding_type\": row.embedding_type,\n",
    "        \"start_segment\": row.start_segment,\n",
    "        \"end_segment\": row.end_segment,\n",
    "        \"segment_length\": row.end_segment+1\n",
    "    }\n",
    "\n",
    "    # Execute this query \n",
    "    cursor.execute(insert_query, insert_data)\n",
    "\n",
    "# Now that we're done with adding all of the data, we'll commit it \n",
    "cnx.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Segment Embeddings\n",
    "Now that I've got some of the whole video embeddings in my index, I want to add some of the video segment embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each of the rows in the tnd_data_df\n",
    "for row in tqdm(list(tnd_segment_embeddings_df.itertuples())):\n",
    "\n",
    "    # We'll also iterate through each of the embeddings in this row \n",
    "    for embedding_dict in row.embedding:\n",
    "\n",
    "        # Create the query from some of the information in this row \n",
    "        insert_query = \"\"\"\n",
    "        REPLACE INTO embeddings\n",
    "            (id, video_id, embedding, embedding_type,\n",
    "            start_segment, end_segment, segment_length)\n",
    "            VALUES (%(id)s, %(video_id)s, %(embedding)s, %(embedding_type)s, \n",
    "                    %(start_segment)s, %(end_segment)s, %(segment_length)s)\n",
    "        \"\"\"\n",
    "\n",
    "        # We'll specify the data that we'll be injecting into the table\n",
    "        insert_data = {\n",
    "            \"id\": f\"{row.video_id}_{embedding_dict['segment_range'][0]}_{embedding_dict['segment_range'][1]}\",\n",
    "            \"video_id\": row.video_id,\n",
    "            \"embedding\": np.array(embedding_dict['embedding']).tobytes(),\n",
    "            \"embedding_type\": \"segment_chunk\",\n",
    "            \"start_segment\": embedding_dict['segment_range'][0],\n",
    "            \"end_segment\": embedding_dict['segment_range'][1],\n",
    "            \"segment_length\": (embedding_dict['segment_range'][1] - embedding_dict['segment_range'][0]) + 1\n",
    "        }\n",
    "\n",
    "        # Execute this query \n",
    "        cursor.execute(insert_query, insert_data)\n",
    "\n",
    "# Now that we're done with adding all of the data, we'll commit it \n",
    "cnx.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcriptions\n",
    "Finally, I want to add some of the transcriptions to the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each of the rows in the tnd_data_df\n",
    "for row in tqdm(list(tnd_transcription_df.itertuples())):\n",
    "\n",
    "    # Create the query for insertion into the transcriptions table\n",
    "    insert_query = \"\"\"\n",
    "    REPLACE INTO transcriptions\n",
    "        (id, segment, seek, start_time, end_time, \n",
    "        transcription_type, text)\n",
    "        VALUES (%(id)s, %(segment)s, %(seek)s, %(start_time)s, \n",
    "                %(end_time)s, %(transcription_type)s, \n",
    "                %(text)s)\n",
    "    \"\"\"\n",
    "\n",
    "    # First, we're going to add the full transcription\n",
    "    full_text_insert_data = {\n",
    "        \"id\": row.video_id,\n",
    "        \"segment\": -1,\n",
    "        \"seek\": 0,\n",
    "        \"start_time\": 0,\n",
    "        \"end_time\": row.transcription_dict[\"segments\"][-1]['end'],\n",
    "        \"transcription_type\": \"full_video\",\n",
    "        \"text\": row.transcription_dict['text'].strip()\n",
    "    }\n",
    "    cursor.execute(insert_query, full_text_insert_data)\n",
    "\n",
    "    # Next, we're going to insert all of the segments for this video\n",
    "    for segment_dict in row.transcription_dict[\"segments\"]:\n",
    "        cur_segment_insert_data = {\n",
    "            \"id\": row.video_id,\n",
    "            \"segment\": segment_dict[\"id\"],\n",
    "            \"seek\": segment_dict[\"seek\"],\n",
    "            \"start_time\": segment_dict[\"start\"],\n",
    "            \"end_time\": segment_dict[\"end\"],\n",
    "            \"transcription_type\": \"segment\",\n",
    "            \"text\": segment_dict[\"text\"]\n",
    "        }\n",
    "        cursor.execute(insert_query, cur_segment_insert_data)\n",
    "\n",
    "# Now that we're done with adding all of the data, we'll commit it \n",
    "cnx.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enriched Video Details\n",
    "I *also* want to add some information to the `enriched_video_details` table! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the query for insertion into the enriched_details table\n",
    "insert_query = \"\"\"\n",
    "REPLACE INTO enriched_video_details\n",
    "    (id, video_type, review_score)\n",
    "    VALUES (%s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "# Create the data necessary for insertion\n",
    "enriched_details_insert_data = [(row.videoId, row.inferred_video_type, row.inferred_review_score)\n",
    "                                for row in tnd_data_df.replace({np.nan: None}).itertuples()]\n",
    "\n",
    "# Insert all of the data\n",
    "cursor.executemany(insert_query, enriched_details_insert_data)\n",
    "\n",
    "# Now that we're done with adding all of the data, we'll commit it\n",
    "cnx.commit()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying the Server\n",
    "Now that I've got some data in the table, I want to try and test querying it. With the help of ChatGPT, I've written the method below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_to_df(query, print_error=False):\n",
    "    '''Query the active MySQL database and return results in a DataFrame'''\n",
    "\n",
    "    # Try to return the results as a DataFrame\n",
    "    try:\n",
    "        # Execute the query\n",
    "        cursor.execute(query)\n",
    "\n",
    "        # Fetch the results \n",
    "        res = cursor.fetchall()\n",
    "\n",
    "        # Return a DataFrame\n",
    "        return pd.DataFrame(res, columns=[i[0] for i in cursor.description])\n",
    "\n",
    "    # If we run into an Exception, return None\n",
    "    except Exception as e:\n",
    "        if (print_error):\n",
    "            print(f\"Ran into the following error:\\n{e}\\nStack trace:\")\n",
    "            print(traceback.format_exc())\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now - we can test this method out! The code below will grab *all* of the video details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query will grab all of the data from the table \n",
    "all_video_details_query = \"\"\"SELECT * FROM video_details\"\"\"\n",
    "\n",
    "# Execute the above query \n",
    "all_video_details_df = query_to_df(all_video_details_query)\n",
    "\n",
    "# Show the first 3 rows\n",
    "all_video_details_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about a query that'll do a little analysis? What's the longest video I have? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query will determine the title of the longest video\n",
    "longest_video_query = \"\"\"\n",
    "SELECT\n",
    "    title,\n",
    "    length\n",
    "FROM\n",
    "    video_details\n",
    "WHERE length = (SELECT MAX(length) FROM video_details)\n",
    "\"\"\"\n",
    "\n",
    "# Execute the above query\n",
    "query_to_df(longest_video_query, print_error=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about the shortest video? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query will determine the title of the shortest video\n",
    "shortest_video_query = \"\"\"\n",
    "SELECT \n",
    "    title,\n",
    "    length\n",
    "FROM\n",
    "    video_details\n",
    "WHERE length = (SELECT MIN(length) FROM video_details)\n",
    "\"\"\"\n",
    "\n",
    "# Execute the above query\n",
    "query_to_df(shortest_video_query, print_error=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about something a little more complicated: \"what's the longest video released in 2018 that had a maximum length of 3 minutes?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query will determine the video described above\n",
    "complicated_query = \"\"\"\n",
    "WITH only_2018 AS (\n",
    "    SELECT id, length\n",
    "    FROM video_details\n",
    "    WHERE YEAR(publish_date) = 2018\n",
    ")\n",
    "SELECT \n",
    "    video_details.id,\n",
    "    video_details.title, \n",
    "    video_details.length,\n",
    "    video_details.url\n",
    "FROM only_2018\n",
    "JOIN video_details ON video_details.id=only_2018.id\n",
    "WHERE video_details.length = (SELECT MAX(length) from only_2018 WHERE length <=300) \n",
    "\"\"\"\n",
    "\n",
    "# Execute the above query\n",
    "query_to_df(complicated_query, print_error=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closing the Cursor\n",
    "Once we're finished with things, we ought to close out the cursor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70b6d7546de29863a58b9c57a86bc7d85299cc84f1fdf81f78934173ede7c021"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
